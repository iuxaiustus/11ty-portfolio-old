---
layout: layouts/works/work_things.njk
tags: post
related:
  - Unity
  - Hololens 2
  - Oculus Quest
cover: ./src/img/things_cover.png
title: >
  Contextual learning with Mixed Reality
date: Created
product: >
  Thesis (Work in Progress)
subtitle: M.Des. Thesis @ OCAD University
summary_title1: Aim
summary1: Reduce Integration Cycle time and improve user onboarding experience

summary_title2: Tools
summary2: Unity, Hololens MRTK3, Node, PyTorch
summary_title3: Timeline
summary3: 2022 - Present

link1: Thesis (Work in Progress)
link1_url: ocadu.ca

context: >
  Since I arrived in Canada about 6 months ago, I’ve been trying to learn French through different techniques. I’ve tried some of the most popular apps such as Duolingo, completed certain French grammar exercises, and watched a bunch of French movies as well. Although I’ve caught some bits of grammar and vocabulary along the way, I feel that these techniques are not efficient. After a bit of research, I realized that conventional technological tools to learn languages are inefficient as they lack a real context. Immersion can significantly accelerate the learning process and I was curious to build an app that could make learning languages fun and highly efficient for me and all the other language learners.

section1_title: Reimagining the way we learn
section1_subtitle: Can we bring learning to life?
section1_content: Context + Mixed Reality = Magic
section1_img: ./src/img/sdkx/cover.png

section2_title: Research Question
section2_content: How can adaptive context-aware systems support interactive mixed reality learning experiences?
section2_img: ./src/img/things_overview.png
section2_img_credits: How Augmented Reality Will Change Education Completely | Florian Radke | TEDxGateway
section3_title: >
  # Prototype 1: Language Learning
section3_content: Things is an app built for Android smart glasses with a camera and a microphone. The app features real-time intelligence to help you learn languages in an immersive context. When users wearing smart glasses look at any object around them, they see what’s that object called in the target language on the HUD(heads up display) screen. It currently supports 3 languages (French, Italian, and Japanese) and allows the users can switch between languages by tapping on the capacitive touch panel on the glasses. The smart glasses display the translation of the object’s name and speak out the pronunciation as well.
section3_img: ./src/img/things_lang.png
section3_img2: ./src/img/things_how.png
section4_title: >
  # Prototype 2: Surface area and Volumes
section4_content:
section4_img: ./src/img/things_math_area.png

section5_title: Further development
section5_img: ./src/img/things_further.png
section5_content: The app is being ported to Hololens 2 and would use its RGB cameras and depth sensors for spatial anchoring. Google Cloud Vision APIs will also be used to support many more object categories and other language APIs to support sentence construction are being added.
---
